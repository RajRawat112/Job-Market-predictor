{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are creating a (.env) file to hide our API_KEY and API_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "# Loading vairable from .env\n",
    "load_dotenv()\n",
    "\n",
    "#Getting them on this file\n",
    "\n",
    "API_ID = os.getenv(\"ADZUNA_APP_ID\")\n",
    "API_KEY = os.getenv(\"ADZUNA_APP_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are calling the API key to extract data from the web database to our pandas dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "url = f\"https://api.adzuna.com/v1/api/jobs/gb/search/{i}?app_id={API_ID}&app_key={API_KEY}&results_per_page=20&what=javascript%20developer&content-type=application/json\"\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for i in range (1,300,1):\n",
    "    response = requests.get(url)  # here the response variable is a object. Then in the next line we are converting response variable into json type.\n",
    "    temp_data = response.json()['results']\n",
    "    temp_df = pd.json_normalize(temp_data)\n",
    "    final_df = pd.concat([final_df,temp_df],ignore_index=True)\n",
    "    time.sleep(1)  # Here we are using this time method to create a small delay so we would hit the server API request limit.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['avg_salary'] = (final_df[\"salary_min\"] + final_df[\"salary_max\"]) / 2\n",
    "final_df= final_df[['title','company.display_name','created','location.display_name','salary_max','salary_min','category.label','avg_salary']]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are doing some EDA(Exploratory data analysis) to better understand the data we are working on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "print(\"Shape of dataset:\", final_df.shape)\n",
    "print(\"\\nColumns:\", final_df.columns.tolist())\n",
    "print(\"\\nMissing values:\\n\", final_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Salary Preprocessing ---\n",
    "avg_salary = (final_df[\"salary_min\"] + final_df[\"salary_max\"]) / 2\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Top Job Titles ---\n",
    "top_titles = final_df[\"title\"].value_counts().head(10)\n",
    "print(\"\\nTop Job Titles:\\n\", top_titles)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(y=top_titles.index, x=top_titles.values)\n",
    "plt.title(\"Top 10 Job Titles\")\n",
    "plt.xlabel(\"Number of Postings\")\n",
    "plt.ylabel(\"Job Title\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>company.display_name</th>\n",
       "      <th>created</th>\n",
       "      <th>location.display_name</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>category.label</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JavaScript Developer - Hybrid (Manchester )</td>\n",
       "      <td>Circle Group</td>\n",
       "      <td>2025-08-20T13:27:38Z</td>\n",
       "      <td>Manchester, Greater Manchester</td>\n",
       "      <td>40000.00</td>\n",
       "      <td>40000.00</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>40000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Full-Stack Javascript Developer – Central Lond...</td>\n",
       "      <td>Nexus Jobs Limited</td>\n",
       "      <td>2025-08-13T14:20:32Z</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>44198.56</td>\n",
       "      <td>44198.56</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>44198.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Javascript Developer</td>\n",
       "      <td>Track24</td>\n",
       "      <td>2025-09-06T00:35:08Z</td>\n",
       "      <td>Finsbury, Central London</td>\n",
       "      <td>60000.00</td>\n",
       "      <td>60000.00</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>60000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Javascript Developer</td>\n",
       "      <td>Lloyds Bank</td>\n",
       "      <td>2025-08-31T17:44:01Z</td>\n",
       "      <td>UK</td>\n",
       "      <td>58410.00</td>\n",
       "      <td>47790.00</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>53100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>JavaScript Developer</td>\n",
       "      <td>Sellick Partnership</td>\n",
       "      <td>2025-09-04T14:19:06Z</td>\n",
       "      <td>Newcastle Upon Tyne, Tyne &amp; Wear</td>\n",
       "      <td>55000.00</td>\n",
       "      <td>48000.00</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>51500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0        JavaScript Developer - Hybrid (Manchester )   \n",
       "1           1  Full-Stack Javascript Developer – Central Lond...   \n",
       "2           2                               Javascript Developer   \n",
       "3           3                               Javascript Developer   \n",
       "4           4                               JavaScript Developer   \n",
       "\n",
       "  company.display_name               created  \\\n",
       "0         Circle Group  2025-08-20T13:27:38Z   \n",
       "1   Nexus Jobs Limited  2025-08-13T14:20:32Z   \n",
       "2              Track24  2025-09-06T00:35:08Z   \n",
       "3          Lloyds Bank  2025-08-31T17:44:01Z   \n",
       "4  Sellick Partnership  2025-09-04T14:19:06Z   \n",
       "\n",
       "              location.display_name  salary_max  salary_min category.label  \\\n",
       "0    Manchester, Greater Manchester    40000.00    40000.00        IT Jobs   \n",
       "1                        London, UK    44198.56    44198.56        IT Jobs   \n",
       "2          Finsbury, Central London    60000.00    60000.00        IT Jobs   \n",
       "3                                UK    58410.00    47790.00        IT Jobs   \n",
       "4  Newcastle Upon Tyne, Tyne & Wear    55000.00    48000.00        IT Jobs   \n",
       "\n",
       "   avg_salary  \n",
       "0    40000.00  \n",
       "1    44198.56  \n",
       "2    60000.00  \n",
       "3    53100.00  \n",
       "4    51500.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FEATURE ENGINEERING\n",
      "----------------------------------------\n",
      " Created 'avg_salary' - target variable for prediction\n",
      " Created 'days_since_posted' - job posting age in days\n",
      " Created 'title_length' - length of job title\n",
      " Created binary features from job titles:\n",
      "   - is_senior: 1794 jobs\n",
      "   - is_fullstack: 2392 jobs\n",
      "   - is_frontend: 299 jobs\n",
      "   - is_backend: 0 jobs\n",
      "   - is_react: 0 jobs\n",
      "   - is_node: 299 jobs\n",
      " Created salary features:\n",
      "   - salary_range: difference between min and max salary\n",
      "   - salary_category: Entry/Mid/Senior/Lead based on salary\n",
      " Created location features:\n",
      "   - is_london: 3289 jobs in London\n",
      "   - is_remote: 0 remote jobs\n",
      " Created 'company_name_length' - proxy for company type\n",
      "\n",
      " FEATURE ENGINEERING SUMMARY:\n",
      "   Original columns: 7\n",
      "   New features created: 12\n",
      "   Total columns now: 21\n",
      "\n",
      " NEW FEATURES OVERVIEW:\n",
      "   avg_salary: 300.0 to 80000.0\n",
      "   days_since_posted: 5 to 155\n",
      "   title_length: 20 to 69\n",
      "   is_senior: 0 to 1\n",
      "   is_fullstack: 0 to 1\n",
      "   is_frontend: 0 to 1\n",
      "   is_backend: 0 to 0\n",
      "   is_react: 0 to 0\n",
      "   is_node: 0 to 1\n",
      "   salary_range: 0.0 to 15000.0\n",
      "   salary_category: {'Senior': 2691, 'Mid': 1794, 'Lead': 1196, 'Entry': 299}\n",
      "   is_london: 0 to 1\n",
      "   is_remote: 0 to 0\n",
      "   company_name_length: 6 to 22\n",
      "\n",
      " Enhanced dataset saved as 'dataset_with_features.csv'\n",
      " Ready for machine learning!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('dataset.csv', index_col=0)\n",
    "\n",
    "# ========================================\n",
    "# FEATURE ENGINEERING\n",
    "# ========================================\n",
    "\n",
    "print(\" FEATURE ENGINEERING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1. Create target variable (average salary)\n",
    "df['avg_salary'] = (df['salary_min'] + df['salary_max']) / 2\n",
    "print(\" Created 'avg_salary' - target variable for prediction\")\n",
    "\n",
    "# 2. Handle datetime and create days since posted (FIXED VERSION)\n",
    "df['created'] = pd.to_datetime(df['created'])\n",
    "\n",
    "# Fix timezone compatibility\n",
    "if df['created'].dt.tz is not None:\n",
    "    current_time = pd.Timestamp.now(tz=df['created'].dt.tz)\n",
    "else:\n",
    "    current_time = pd.Timestamp.now()\n",
    "\n",
    "df['days_since_posted'] = (current_time - df['created']).dt.days\n",
    "df['days_since_posted'] = df['days_since_posted'].clip(lower=0)  # Remove negative values\n",
    "print(\" Created 'days_since_posted' - job posting age in days\")\n",
    "\n",
    "# 3. Title-based features\n",
    "df['title_length'] = df['title'].str.len()\n",
    "print(\" Created 'title_length' - length of job title\")\n",
    "\n",
    "# 4. Binary features from job titles (1 = True, 0 = False)\n",
    "df['is_senior'] = df['title'].str.contains('Senior|Lead|Principal', case=False, na=False).astype(int)\n",
    "df['is_fullstack'] = df['title'].str.contains('Fullstack|Full Stack|Full-Stack', case=False, na=False).astype(int)\n",
    "df['is_frontend'] = df['title'].str.contains('Frontend|Front End|Front-End', case=False, na=False).astype(int)\n",
    "df['is_backend'] = df['title'].str.contains('Backend|Back End|Back-End', case=False, na=False).astype(int)\n",
    "df['is_react'] = df['title'].str.contains('React', case=False, na=False).astype(int)\n",
    "df['is_node'] = df['title'].str.contains('Node|NodeJS|Node.js', case=False, na=False).astype(int)\n",
    "\n",
    "print(\" Created binary features from job titles:\")\n",
    "print(f\"   - is_senior: {df['is_senior'].sum()} jobs\")\n",
    "print(f\"   - is_fullstack: {df['is_fullstack'].sum()} jobs\") \n",
    "print(f\"   - is_frontend: {df['is_frontend'].sum()} jobs\")\n",
    "print(f\"   - is_backend: {df['is_backend'].sum()} jobs\")\n",
    "print(f\"   - is_react: {df['is_react'].sum()} jobs\")\n",
    "print(f\"   - is_node: {df['is_node'].sum()} jobs\")\n",
    "\n",
    "# 5. Salary-based features\n",
    "df['salary_range'] = df['salary_max'] - df['salary_min']\n",
    "df['salary_category'] = pd.cut(df['avg_salary'], \n",
    "                              bins=[0, 30000, 50000, 70000, float('inf')], \n",
    "                              labels=['Entry', 'Mid', 'Senior', 'Lead'])\n",
    "print(\" Created salary features:\")\n",
    "print(f\"   - salary_range: difference between min and max salary\")\n",
    "print(f\"   - salary_category: Entry/Mid/Senior/Lead based on salary\")\n",
    "\n",
    "# 6. Location-based features\n",
    "df['is_london'] = df['location.display_name'].str.contains('London', case=False, na=False).astype(int)\n",
    "df['is_remote'] = df['location.display_name'].str.contains('Remote|Work from home', case=False, na=False).astype(int)\n",
    "print(\" Created location features:\")\n",
    "print(f\"   - is_london: {df['is_london'].sum()} jobs in London\")\n",
    "print(f\"   - is_remote: {df['is_remote'].sum()} remote jobs\")\n",
    "\n",
    "# 7. Company name length (proxy for company size/type)\n",
    "df['company_name_length'] = df['company.display_name'].str.len()\n",
    "print(\" Created 'company_name_length' - proxy for company type\")\n",
    "\n",
    "# 8. Summary statistics\n",
    "print(f\"\\n FEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"   Original columns: {len(['title', 'company.display_name', 'created', 'location.display_name', 'salary_max', 'salary_min', 'category.label'])}\")\n",
    "print(f\"   New features created: 12\")\n",
    "print(f\"   Total columns now: {len(df.columns)}\")\n",
    "\n",
    "# 9. Display new features summary\n",
    "new_features = ['avg_salary', 'days_since_posted', 'title_length', 'is_senior', \n",
    "               'is_fullstack', 'is_frontend', 'is_backend', 'is_react', 'is_node',\n",
    "               'salary_range', 'salary_category', 'is_london', 'is_remote', 'company_name_length']\n",
    "\n",
    "print(f\"\\n NEW FEATURES OVERVIEW:\")\n",
    "for feature in new_features:\n",
    "    if feature in df.columns:\n",
    "        if df[feature].dtype in ['int64', 'float64']:\n",
    "            print(f\"   {feature}: {df[feature].min()} to {df[feature].max()}\")\n",
    "        else:\n",
    "            print(f\"   {feature}: {df[feature].value_counts().to_dict()}\")\n",
    "\n",
    "# Save the enhanced dataset\n",
    "df.to_csv('dataset_with_features.csv')\n",
    "print(f\"\\n Enhanced dataset saved as 'dataset_with_features.csv'\")\n",
    "print(f\" Ready for machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing using Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATA PREPROCESSING WITH COLUMNTRANSFORMER\n",
      "==================================================\n",
      "Dataset shape: (5980, 21)\n",
      "\n",
      "Features to use:\n",
      "  Categorical: 4 features\n",
      "  Numerical: 12 features\n",
      "  Total: 16 features\n",
      "\n",
      "Data prepared:\n",
      "  X shape: (5980, 16)\n",
      "  y range: £300 to £80,000\n",
      "\n",
      "Data split:\n",
      "  Training: 4784 samples\n",
      "  Testing: 1196 samples\n",
      "\n",
      "ColumnTransformer created with:\n",
      "  StandardScaler for numerical features\n",
      "  OneHotEncoder for categorical features\n",
      "\n",
      "Applying preprocessing...\n",
      "  Original features: 16\n",
      "  Processed features: 42\n",
      "\n",
      "Feature transformation summary:\n",
      "  Numerical features: 12\n",
      "  Categorical features expanded to: 30\n",
      "\n",
      " PREPROCESSING COMPLETE!\n",
      "Files saved:\n",
      "  - preprocessor.pkl (ColumnTransformer)\n",
      "  - X_train_processed.npy ((4784, 42))\n",
      "  - X_test_processed.npy ((1196, 42))\n",
      "  - y_train.npy ((4784,))\n",
      "  - y_test.npy ((1196,))\n",
      "  - feature_names.txt (42 features)\n",
      "\n",
      " Ready for model training!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "# Load the enhanced dataset\n",
    "df = pd.read_csv('dataset_with_features.csv', index_col=0)\n",
    "\n",
    "print(\" DATA PREPROCESSING WITH COLUMNTRANSFORMER\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Define target variable\n",
    "target = 'avg_salary'\n",
    "\n",
    "# Define feature groups\n",
    "categorical_features = [\n",
    "    'location.display_name',\n",
    "    'company.display_name', \n",
    "    'category.label',\n",
    "    'salary_category'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'title_length',\n",
    "    'days_since_posted',\n",
    "    'is_senior',\n",
    "    'is_fullstack',\n",
    "    'is_frontend',\n",
    "    'is_backend',\n",
    "    'is_react',\n",
    "    'is_node',\n",
    "    'salary_range',\n",
    "    'is_london',\n",
    "    'is_remote',\n",
    "    'company_name_length'\n",
    "]\n",
    "\n",
    "all_features = categorical_features + numerical_features\n",
    "\n",
    "print(f\"\\nFeatures to use:\")\n",
    "print(f\"  Categorical: {len(categorical_features)} features\")\n",
    "print(f\"  Numerical: {len(numerical_features)} features\")\n",
    "print(f\"  Total: {len(all_features)} features\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[all_features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna('Unknown')\n",
    "\n",
    "print(f\"\\nData prepared:\")\n",
    "print(f\"  X shape: {X.shape}\")\n",
    "print(f\"  y range: £{y.min():,.0f} to £{y.max():,.0f}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training: {X_train.shape[0]} samples\")\n",
    "print(f\"  Testing: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Create ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print(f\"\\nColumnTransformer created with:\")\n",
    "print(f\"  StandardScaler for numerical features\")\n",
    "print(f\"  OneHotEncoder for categorical features\")\n",
    "\n",
    "# Fit and transform\n",
    "print(f\"\\nApplying preprocessing...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"  Original features: {X_train.shape[1]}\")\n",
    "print(f\"  Processed features: {X_train_processed.shape[1]}\")\n",
    "\n",
    "# Get feature names for reference\n",
    "try:\n",
    "    numerical_names = numerical_features\n",
    "    categorical_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "    all_feature_names = numerical_names + list(categorical_names)\n",
    "    \n",
    "    print(f\"\\nFeature transformation summary:\")\n",
    "    print(f\"  Numerical features: {len(numerical_names)}\")\n",
    "    print(f\"  Categorical features expanded to: {len(categorical_names)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Could not extract feature names: {e}\")\n",
    "    all_feature_names = [f\"feature_{i}\" for i in range(X_train_processed.shape[1])]\n",
    "\n",
    "# Save preprocessing artifacts\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "np.save('X_train_processed.npy', X_train_processed)\n",
    "np.save('X_test_processed.npy', X_test_processed)  \n",
    "np.save('y_train.npy', y_train.values)\n",
    "np.save('y_test.npy', y_test.values)\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_names.txt', 'w') as f:\n",
    "    for name in all_feature_names:\n",
    "        f.write(name + '\\n')\n",
    "\n",
    "print(f\"\\n PREPROCESSING COMPLETE!\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  - preprocessor.pkl (ColumnTransformer)\")\n",
    "print(f\"  - X_train_processed.npy ({X_train_processed.shape})\")\n",
    "print(f\"  - X_test_processed.npy ({X_test_processed.shape})\")\n",
    "print(f\"  - y_train.npy ({y_train.shape})\")\n",
    "print(f\"  - y_test.npy ({y_test.shape})\")\n",
    "print(f\"  - feature_names.txt ({len(all_feature_names)} features)\")\n",
    "\n",
    "print(f\"\\n Ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
